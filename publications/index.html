<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Publications | Tianfang  Zhang</title>
    <meta name="author" content="Tianfang  Zhang">
    <meta name="description" content="Authors marked by * contributed equally.">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%93&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://tianfang-zhang.github.io/publications/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">Tianfang <span class="font-weight-bold">Zhang</span></a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">Publications</h1>
            <p class="post-description">Authors marked by * contributed equally.</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2024</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge">Arxiv</abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/casvit.png">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="zhang2024cas" class="col-sm-8">
        <!-- Title -->
        <div class="title">CAS-ViT: Convolutional Additive Self-attention Vision Transformers for Efficient Mobile Applications</div>
        <!-- Author -->
        <div class="author">
        

        <em>Tianfang Zhang</em>, <a href="https://di.ku.dk/english/staff/?pure=en/persons/702491" rel="external nofollow noopener" target="_blank">Lei Li</a>, Yang Zhou, Wentao Liu, Chen Qian, and Xiangyang Ji</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em></em> 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="http://arxiv.org/abs/2408.03703" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/Tianfang-Zhang/CAS-ViT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Vision Transformers (ViTs) mark a revolutionary advance in neural networks with their token mixer’s powerful global context capability. However, the pairwise token affinity and complex matrix operations limit its deployment on resource-constrained scenarios and real-time applications, such as mobile devices, although considerable efforts have been made in previous works. In this paper, we introduce CAS-ViT: Convolutional Additive Self-attention Vision Transformers, to achieve a balance between efficiency and performance in mobile applications. Firstly, we argue that the capability of token mixers to obtain global contextual information hinges on multiple information interactions, such as spatial and channel domains. Subsequently, we construct a novel additive similarity function following this paradigm and present an efficient implementation named Convolutional Additive Token Mixer (CATM). This simplification leads to a significant reduction in computational overhead. We evaluate CAS-ViT across a variety of vision tasks, including image classification, object detection, instance segmentation, and semantic segmentation. Our experiments, conducted on GPUs, ONNX, and iPhones, demonstrate that CAS-ViT achieves a competitive performance when compared to other state-of-the-art backbones, establishing it as a viable option for efficient mobile vision applications.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge">WACV 2024</abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/rpcanet.png">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="wu2023rpcanet" class="col-sm-8">
        <!-- Title -->
        <div class="title">RPCANet: Deep Unfolding RPCA Based Infrared Small Target Detection</div>
        <!-- Author -->
        <div class="author">
        

        Fengyi Wu*, <em>Tianfang Zhang*</em>, <a href="https://di.ku.dk/english/staff/?pure=en/persons/702491" rel="external nofollow noopener" target="_blank">Lei Li</a>, Yian Huang, and <a href="https://www.sice.uestc.edu.cn/info/1302/5086.htm" rel="external nofollow noopener" target="_blank">Zhenming Peng</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>IEEE/CVF Winter Conference on Applications of Computer Vision</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="http://arxiv.org/abs/2311.00917" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="https://github.com/fengyiwu98/RPCANet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep learning (DL) networks have achieved remarkable performance in infrared small target detection (ISTD). However, these structures exhibit a deficiency in interpretability and are widely regarded as black boxes, as they disregard domain knowledge in ISTD. To alleviate this issue, this work proposes an interpretable deep network for detecting infrared dim targets, dubbed RPCANet. Specifically, our approach formulates the ISTD task as sparse target extraction, low-rank background estimation, and image reconstruction in a relaxed Robust Principle Component Analysis (RPCA) model. By unfolding the iterative optimization updating steps into a deep-learning framework, time-consuming and complex matrix calculations are replaced by theory-guided neural networks. RPCANet detects targets with clear interpretability and preserves the intrinsic image feature, instead of directly transforming the detection task into a matrix decomposition problem. Extensive experiments substantiate the effectiveness of our deep unfolding framework and demonstrate its trustworthy results, surpassing baseline methods in both qualitative and quantitative evaluations.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge">KBS</abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/ctnet.png">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="zhang2023optimization" class="col-sm-8">
        <!-- Title -->
        <div class="title">Optimization-inspired Cumulative Transmission Network for image compressive sensing</div>
        <!-- Author -->
        <div class="author">
        

        <em>Tianfang Zhang*</em>, <a href="https://di.ku.dk/english/staff/?pure=en/persons/702491" rel="external nofollow noopener" target="_blank">Lei Li*</a>, and <a href="https://www.sice.uestc.edu.cn/info/1302/5086.htm" rel="external nofollow noopener" target="_blank">Zhenming Peng</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Knowledge-Based Systems</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S095070512300713X" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://github.com/Tianfang-Zhang/CT-Net" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Compressive Sensing (CS) techniques enable accurate signal reconstruction with few measurements. Deep Unfolding Networks (DUNs) have recently been shown to increase the efficiency of CS by emulating iterative CS optimization procedures by neural networks. However, most of these DUNs suffer from redundant update procedures or complex matrix operations, which can impair their reconstruction performances. Here we propose the optimization-inspired Cumulative Transmission Network (CT-Net), a DUN approach for natural image CS. We formulate an optimization procedure introducing an auxiliary variable similar to Half Quadratic Splitting (HQS). Unfolding this procedure defines the basic structure of our neural architecture, which is then further refined. A CT-Net is composed of Reconstruction Fidelity Modules (RFMs) for minimizing the reconstruction error and Constraint Gradient Approximation (CGA) modules for approximating (the gradient of) sparsity constraints instead of relying on an analytic solutions such as soft-thresholding. Furthermore, a lightweight Cumulative Transmission (CT) between CGAs in each reconstruction stage is proposed to facilitate a better feature representation. Experiments on several widely used natural image benchmarks illustrate the effectiveness of CT-Net with significant performance improvements and fewer network parameters compared to existing state-of-the-art methods. The experiments also demonstrate the scene and noise robustness of the proposed method.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge"><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7" rel="external nofollow noopener" target="_blank">TAES</a></abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/agpcnet.jpg">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="zhang2023attention" class="col-sm-8">
        <!-- Title -->
        <div class="title">Attention-Guided Pyramid Context Networks for Detecting Infrared Small Target Under Complex Background</div>
        <!-- Author -->
        <div class="author">
        

        <em>Tianfang Zhang</em>, <a href="https://di.ku.dk/english/staff/?pure=en/persons/702491" rel="external nofollow noopener" target="_blank">Lei Li</a>, Siying Cao, Tian Pu, and <a href="https://www.sice.uestc.edu.cn/info/1302/5086.htm" rel="external nofollow noopener" target="_blank">Zhenming Peng</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>IEEE Transactions on Aerospace and Electronic Systems</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="https://ieeexplore.ieee.org/abstract/document/10024907" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://github.com/Tianfang-Zhang/AGPCNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Infrared small target detection techniques remain a challenging task due to the complex background. To overcome this problem, by exploring context information, this research presents a data-driven approach called Attention-Guided Pyramid Context Network (AGPCNet). Specifically, we design Attention-Guided Context Block (AGCB) and perceive pixel correlations within and between patches at specific scales via Local Semantic Association (LSA) and Global Context Attention (GCA) respectively. Then the contextual information from multiple scales is fused by Context Pyramid Module (CPM) to achieve better feature representation. In the upsampling stage, we fuse the low and deep semantics through Asymmetric Fusion Module (AFM) to retain more information about small targets. The experimental results illustrate that AGPCNet has achieved state-of-the-art performance on three available infrared small target datasets.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge">Computers &amp; Graphics</abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/maskfpan.png">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="li2023mask" class="col-sm-8">
        <!-- Title -->
        <div class="title">Mask-FPAN: Semi-supervised Face Parsing in the Wild with De-occlusion and UV GAN</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://di.ku.dk/english/staff/?pure=en/persons/702491" rel="external nofollow noopener" target="_blank">Lei Li</a>, <em>Tianfang Zhang</em>, <a href="https://xxxy.lzu.edu.cn/shiziduiwu/jiaoshiduiwu/fujiaoshou/2023/0911/227147.html" rel="external nofollow noopener" target="_blank">Zhongfeng Kang</a>, and Xikun Jiang</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Computers &amp; Graphics</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0097849323001735" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The field of fine-grained semantic segmentation for a person’s face and head, which includes identifying facial parts and head components, has made significant progress in recent years. However, this task remains challenging due to the difficulty of considering ambiguous occlusions and large pose variations. To address these difficulties, we propose a new framework called Mask-FPAN. Our framework includes a de-occlusion module that learns to parse occluded faces in a semi-supervised manner, taking into account face landmark localization, face occlusion estimations, and detected head poses. Additionally, we improve the robustness of 2D face parsing by combining a 3D morphable face model with the UV GAN. We also introduce two new datasets, named FaceOccMask-HQ and CelebAMaskOcc-HQ, to aid in face parsing work. Our proposed Mask-FPAN framework successfully addresses the challenge of face parsing in the wild and achieves significant performance improvements, with a mIoU increase from 0.7353 to 0.9013 compared to the current state-of-the-art on challenging face datasets.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge">NMI</abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/buildseg.png">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="li2023buildseg" class="col-sm-8">
        <!-- Title -->
        <div class="title">BuildSeg BuildSeg: A General Framework for the Segmentation of Buildings</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://di.ku.dk/english/staff/?pure=en/persons/702491" rel="external nofollow noopener" target="_blank">Lei Li</a>, <em>Tianfang Zhang</em>, Stefan Oehmcke, Fabian Gieseke, and <a href="https://christian-igel.github.io/" rel="external nofollow noopener" target="_blank">Christian Igel</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Nordic Machine Intelligence</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="https://journals.uio.no/NMI/article/view/10152" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Building segmentation from aerial images and 3D laser scanning (LiDAR) is a challenging task due to the diversity of backgrounds, building textures, and image quality. While current research using different types of convolutional and transformer networks has considerably improved the performance on this task, more precise and accurate segmentation methods for buildings are desirable for applications such as automatic mapping. In this study, we propose a general framework termed BuildSeg employing a generic approach that can be quickly applied to segment buildings. Different data sources were combined to increase generalization performance. The approach yields good results for different data sources as shown by experiments on high-resolution multi-spectral and LiDAR imagery of cities in Norway, Denmark, and France. We applied ConvNeXt and SegFormer-based models on the high-resolution aerial image dataset from the MapAI-competition. The methods achieved an IoU of 0.7902 and a boundary IoU of 0.6185 on the test set. We used post-processing to account for the rectangular shape of the objects.This increased the boundary IOU from 0.6185 to 0.6189.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr">
<abbr class="badge">ICCC 2022</abbr>
                <span class="badge award">Oral</span>
</div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/lrcsnet.png">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="zhang2022lrcsnet" class="col-sm-8">
        <!-- Title -->
        <div class="title">LR-CSNet: Low-rank Deep Unfolding Network for Image Compressive Sensing</div>
        <!-- Author -->
        <div class="author">
        

        <em>Tianfang Zhang</em>, <a href="https://di.ku.dk/english/staff/?pure=en/persons/702491" rel="external nofollow noopener" target="_blank">Lei Li</a>, <a href="https://christian-igel.github.io/" rel="external nofollow noopener" target="_blank">Christian Igel</a>, Stefan Oehmcke, Fabian Gieseke, and <a href="https://www.sice.uestc.edu.cn/info/1302/5086.htm" rel="external nofollow noopener" target="_blank">Zhenming Peng</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the 8th IEEE International Conference on Computer and Communications</em>, 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="http://arxiv.org/abs/2212.09088" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a>
            <a href="http://www-engineeringvillage-com-s.vpn.uestc.edu.cn:8118/app/doc/?docid=cpx_M183ebca618790c4a270M7b8f10178165143&amp;pageSize=25&amp;index=1&amp;searchId=d5a68db9634b471d90ae83ce0532635a&amp;resultsCount=2&amp;usageZone=resultslist&amp;usageOrigin=searchresults&amp;searchType=Quick" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://github.com/Tianfang-Zhang/LowRank-CSNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep unfolding networks (DUNs) have proven to be a viable approach to compressive sensing (CS). In this work, we propose a DUN called low-rank CS network (LR-CSNet) for natural image CS. Real-world image patches are often well-represented by low-rank approximations. LR-CSNet exploits this property by adding a low-rank prior to the CS optimization task. We derive a corresponding iterative optimization procedure using variable splitting, which is then translated to a new DUN architecture. The architecture uses low-rank generation modules (LRGMs), which learn low-rank matrix factorizations, as well as gradient descent and proximal mappings (GDPMs), which are proposed to extract high-frequency features to refine image details. In addition, the deep features generated at each reconstruction stage in the DUN are transferred between stages to boost the performance. Our extensive experiments on three widely considered datasets demonstrate the promising performance of LR-CSNet compared to state-of-the-art methods in natural image CS.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge"><a href="https://www.sciencedirect.com/journal/neurocomputing" rel="external nofollow noopener" target="_blank">Neurocomputing</a></abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/srws.jpg">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="zhang2021infrared" class="col-sm-8">
        <!-- Title -->
        <div class="title">Infrared small target detection via self-regularized weighted sparse model</div>
        <!-- Author -->
        <div class="author">
        

        <em>Tianfang Zhang</em>, <a href="https://www.sice.uestc.edu.cn/info/1302/5086.htm" rel="external nofollow noopener" target="_blank">Zhenming Peng</a>, Hao Wu, Yanmin He, Chaohai Li, and Chunping Yang</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Neurocomputing</em>, 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="https://www.sciencedirect.com/science/article/pii/S0925231220313461" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://github.com/Tianfang-Zhang/SRWS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Infrared search and track (IRST) system is widely used in many fields, however, it’s still a challenging task to detect infrared small targets in complex background. This paper proposed a novel detection method called self-regularized weighted sparse (SRWS) model. The algorithm is designed for the hypothesis that data may come from multi-subspaces. And the overlapping edge information (OEI), which can detect the background structure information, is applied to constrain the sparse item and enhance the accuracy. Furthermore, the self-regularization item is applied to mine the potential information in background, and extract clutter from multi-subspaces. Therefore, the infrared small target detection problem is transformed into an optimization problem. By combining the optimization function with alternating direction method of multipliers (ADMM), we explained the solution method of SRWS and optimized its iterative convergence condition. A series of experimental results show that the proposed method outperforms state-of-the-art baselines.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge"><a href="https://www.mdpi.com/journal/remotesensing" rel="external nofollow noopener" target="_blank">Remote Sens.</a></abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/nolc.png">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="zhang2019infrared" class="col-sm-8">
        <!-- Title -->
        <div class="title">Infrared small target detection based on non-convex optimization with Lp-norm constraint</div>
        <!-- Author -->
        <div class="author">
        

        <em>Tianfang Zhang</em>, Hao Wu, <a href="https://scholar.google.com/citations?user=Rmsc214AAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Yuhan Liu</a>, Lingbing Peng, Chunping Yang, and <a href="https://www.sice.uestc.edu.cn/info/1302/5086.htm" rel="external nofollow noopener" target="_blank">Zhenming Peng</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Remote Sensing</em>, 2019
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="https://www.mdpi.com/2072-4292/11/5/559" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
            <a href="https://github.com/Tianfang-Zhang/NOLC" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The infrared search and track (IRST) system has been widely used, and the field of infrared small target detection has also received much attention. Based on this background, this paper proposes a novel infrared small target detection method based on non-convex optimization with Lp-norm constraint (NOLC). The NOLC method strengthens the sparse item constraint with Lp-norm while appropriately scaling the constraints on low-rank item, so the NP-hard problem is transformed into a non-convex optimization problem. First, the infrared image is converted into a patch image and is secondly solved by the alternating direction method of multipliers (ADMM). In this paper, an efficient solver is given by improving the convergence strategy. The experiment shows that NOLC can accurately detect the target and greatly suppress the background, and the advantages of the NOLC method in detection efficiency and computational efficiency are verified.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge"><a href="https://www.mdpi.com/journal/remotesensing" rel="external nofollow noopener" target="_blank">Remote Sens.</a></abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/structure.png">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="huang2019structure" class="col-sm-8">
        <!-- Title -->
        <div class="title">Structure-adaptive clutter suppression for infrared small target detection: Chain-growth filtering</div>
        <!-- Author -->
        <div class="author">
        

        Suqi Huang, <a href="https://scholar.google.com/citations?user=Rmsc214AAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Yuhan Liu</a>, Yanmin He, <em>Tianfang Zhang</em>, and <a href="https://www.sice.uestc.edu.cn/info/1302/5086.htm" rel="external nofollow noopener" target="_blank">Zhenming Peng</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Remote Sensing</em>, 2019
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="https://www.mdpi.com/2072-4292/12/1/47" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Robust detection of infrared small target is an important and challenging task in many photoelectric detection systems. Using the difference of a specific feature between the target and the background, various detection methods were proposed in recent decades. However, most methods extract the feature in a region with fixed shape, especially in a rectangular region, which causes a problem: when faced with complex-shape clutters, the rectangular region involves the pixels inside and outside the clutters, and the significant grey-level difference among these pixels leads to a relatively large feature in the clutter area, interfering with the target detection. In this paper, we propose a structure-adaptive clutter suppression method, called chain-growth filtering, for robust infrared small target detection. The well-designed filtering model can adjust its shape to fit various clutter structures such as lines, curves and irregular edges, and thus has a more robust clutter suppression capability than the fixed-shape feature extraction strategy. In addition, the proposed method achieves a considerable anti-noise ability by employing guided filter as a preprocessing approach and enjoys the capability of multi-scale target detection without complex parameter tuning. In the experiment, we evaluate the performance of the detection method through 12 typical infrared scenes which contain different types of clutters. Compared with seven state-of-the-art methods, the proposed method shows the superior clutter-suppression effects for various types of clutters and the excellent detection performance for various scenes.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge">Symmetry</abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/symmetry.jpg">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="peng2019infrared" class="col-sm-8">
        <!-- Title -->
        <div class="title">Infrared dim target detection using shearlet’s kurtosis maximization under non-uniform background</div>
        <!-- Author -->
        <div class="author">
        

        Lingbing Peng, <em>Tianfang Zhang</em>, <a href="https://scholar.google.com/citations?user=Rmsc214AAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Yuhan Liu</a>, Meihui Li, and <a href="https://www.sice.uestc.edu.cn/info/1302/5086.htm" rel="external nofollow noopener" target="_blank">Zhenming Peng</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Symmetry</em>, 2019
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="https://www.mdpi.com/2073-8994/11/5/723" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A novel method based on multiscale and multidirectional feature fusion in the shearlet transform domain and kurtosis maximization for detecting the dim target in infrared images with a low signal-to-noise ratio (SNR) and serious interference caused by a cluttered and non-uniform background is presented in this paper. First, an original image is decomposed using the shearlet transform with translation invariance. Second, various directions of high-frequency subbands are fused and the corresponding kurtosis of fused image is computed. The targets can be enhanced by strengthening the column with maximum kurtosis. Then, processed high-frequency subbands on different scales of images are merged. Finally, the dim targets are detected by an adaptive threshold with a maximum contrast criterion (MCC). The experimental results show that the proposed method has good performance for infrared target detection in comparison with the nonsubsampled contourlet transform (NSCT) method.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge">Opt. Rev.</abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/mdmshb.png">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="peng2019infraredsmall" class="col-sm-8">
        <!-- Title -->
        <div class="title">Infrared small-target detection based on multi-directional multi-scale high-boost response</div>
        <!-- Author -->
        <div class="author">
        

        Lingbing Peng, <em>Tianfang Zhang</em>, Suqi Huang, Tian Pu, <a href="https://scholar.google.com/citations?user=Rmsc214AAAAJ&amp;hl=zh-CN" rel="external nofollow noopener" target="_blank">Yuhan Liu</a>, Yuxiao Lv, Yunchang Zheng, and <a href="https://www.sice.uestc.edu.cn/info/1302/5086.htm" rel="external nofollow noopener" target="_blank">Zhenming Peng</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Optical Review</em>, 2019
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="https://link.springer.com/article/10.1007/s10043-019-00543-1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>As of late, infrared (IR) small-target detection technology is broadly utilized in low-altitude monitoring frameworks, target-tracking frameworks, precise guidance frameworks and forest fire prevention frameworks. In this paper, we propose an infrared small-target detection strategy based on multi-directional multi-scale high-boost response (MDMSHB). First, an eight-direction filtering template is proposed, which can consider the directional information of the image and significantly suppress heterogeneous background such as cloud, linear interference and interface like ocean–sky background. Then, a map based on multi-directional multi-scale high-boost response (MDMSHB map) is calculated. Finally, a straightforward threshold segmentation technique is utilized to get the detection result. The simulation results comparing this method with the four state-of-the-art strategies in six sequences demonstrate that the proposed strategy can adequately suppress heterogeneous background and arbitrary noise. The approach can improve detection rate and reduce false alert rate as well.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-3 no-gutters">
<div class="row no-gutters">
            <div class="col abbr"><abbr class="badge"><a href="https://www.mdpi.com/journal/remotesensing" rel="external nofollow noopener" target="_blank">Remote Sens.</a></abbr></div>
          </div>
<!-- <div class="w-100"></div> --><div class="row no-gutters">
            <div class="col preview">
              <img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/nram.png">
</div>
          </div>
</div>

        <!-- Entry bib key -->
        <div id="zhang2018infrared" class="col-sm-8">
        <!-- Title -->
        <div class="title">Infrared Small Target Detection via Non-convex Rank Approximation Minimization Joint l2,1 Norm</div>
        <!-- Author -->
        <div class="author">
        

        Landan Zhang, Lingbing Peng, <em>Tianfang Zhang</em>, Siying Cao, and <a href="https://www.sice.uestc.edu.cn/info/1302/5086.htm" rel="external nofollow noopener" target="_blank">Zhenming Peng</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Remote Sensing</em>, 2018
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">abstract</a>
            <a href="https://www.mdpi.com/2072-4292/10/11/1821" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>To improve the detection ability of infrared small targets in complex backgrounds, a novel method based on non-convex rank approximation minimization joint l2,1 norm (NRAM) was proposed. Due to the defects of the nuclear norm and l1 norm, the state-of-the-art infrared image-patch (IPI) model usually leaves background residuals in the target image. To fix this problem, a non-convex, tighter rank surrogate and weighted l1 norm are instead utilized, which can suppress the background better while preserving the target efficiently. Considering that many state-of-the-art methods are still unable to fully suppress sparse strong edges, the structured l2,1 norm was introduced to wipe out the strong residuals. Furthermore, with the help of exploiting the structured norm and tighter rank surrogate, the proposed model was more robust when facing various complex or blurry scenes. To solve this non-convex model, an efficient optimization algorithm based on alternating direction method of multipliers (ADMM) plus difference of convex (DC) programming was designed. Extensive experimental results illustrate that the proposed method not only shows superiority in background suppression and target enhancement, but also reduces the computational complexity compared with other baselines.</p>
          </div>
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2024 Tianfang  Zhang. 
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
